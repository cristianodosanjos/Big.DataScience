{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b05493bf",
   "metadata": {},
   "source": [
    "# <<< Made by Cristiano Dos Anjos >>>\n",
    "cristianodosanjos019@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bbeda5",
   "metadata": {},
   "source": [
    "### ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c018e5",
   "metadata": {},
   "source": [
    "### THIS IS THE SECUND PART OF A PROJECT OF CHURN MODELING.\n",
    "### The first part of this project can be accessed by the following link: \n",
    "\n",
    "https://github.com/cristianodosanjos/Big.DataScience/blob/main/Bank%20Customers%20Churn%20(1).ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bed57d",
   "metadata": {},
   "source": [
    "At this part of our project, we will create a machine learning model for deliver who is the customer that want to leave from our bank."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce7377a",
   "metadata": {},
   "source": [
    "#### About this dataset..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3ff162",
   "metadata": {},
   "source": [
    "+ We will use a file of a unknow bank, I got this data from kaggle website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b86670",
   "metadata": {},
   "source": [
    "Context: A dataset which contain some customers who are withdrawing their account from the bank due to some loss and other issues with the help this data we try to analyse and maintain accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bee6e9d",
   "metadata": {},
   "source": [
    "Content: What's inside is more than just rows and columns. Make it easy for others to get started by describing how you acquired the data and what time period it represents, too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f8b73",
   "metadata": {},
   "source": [
    "#### Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1168653a",
   "metadata": {},
   "source": [
    "#### Importing libraries..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3d351b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0325503d",
   "metadata": {},
   "source": [
    "#### Finding our dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8df90ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>For-sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  RowNumber  CustomerId   Surname  CreditScore Geography  Gender  \\\n",
       "0           0          1    15634602  Hargrave          619    France  Female   \n",
       "1           1          2    15647311      Hill          608     Spain  Female   \n",
       "2           2          3    15619304      Onio          502    France  Female   \n",
       "3           3          4    15701354      Boni          699    France  Female   \n",
       "4           4          5    15737888  Mitchell          850     Spain  Female   \n",
       "\n",
       "   Age  Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0   42       2       0.00              1          1               1   \n",
       "1   41       1   83807.86              1          0               1   \n",
       "2   42       8  159660.80              3          1               0   \n",
       "3   39       1       0.00              2          0               0   \n",
       "4   43       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  For-sum  \n",
       "0        101348.88       1        1  \n",
       "1        112542.58       0        1  \n",
       "2        113931.57       1        1  \n",
       "3         93826.63       0        1  \n",
       "4         79084.10       0        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/tyrslayer/Documents/ipynb.Apo$tila$/UltimaPastaDeProjetos/ChurnFile.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c90e41",
   "metadata": {},
   "source": [
    "This dataset was explored and prepared at the previous part. So let's get started the second part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61b5d1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0           int64\n",
       "RowNumber            int64\n",
       "CustomerId           int64\n",
       "Surname             object\n",
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "For-sum              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1c932a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']].values\n",
    "y = df['Exited'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c9620e",
   "metadata": {},
   "source": [
    "Our new variable X will be the params of our model, the variable y will be the predicted response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1e8c6e",
   "metadata": {},
   "source": [
    "We need make some changes. Our model of machine can't perform with columns in format of object, it will be chaged to integers by another model from library preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0241a354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['France', 'Spain', 'France', 'France', 'Spain', 'Spain', 'France'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,1][:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02687e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbg = preprocessing.LabelEncoder().fit(['France', 'Spain', 'Germany'])\n",
    "X[:,1] = lbg.transform(X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6733f22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Female', 'Female', 'Female', ..., 'Female', 'Male', 'Female'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd6a4149",
   "metadata": {},
   "outputs": [],
   "source": [
    "lba = preprocessing.LabelEncoder().fit(['Male', 'Female'])\n",
    "X[:,2] = lba.transform(X[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b5f973",
   "metadata": {},
   "source": [
    "Now let's be using a method from the library \"model selection\", this method called \"train_test_split\", will be used to split the data for us get trained and posteriorly test our data. We are going to train 65% of data, and get testing 35%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de74930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size= 0.35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caee270",
   "metadata": {},
   "source": [
    "Our will be training 65% of data, so this model will have a lot of params for identify parttens in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0979601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "rfc = RandomForestClassifier(max_depth=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e57b59db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08715e7",
   "metadata": {},
   "source": [
    "In the line above there are our first machine learning model's, called Logistic Regression. Logistic regression is the appropriate regression analysis to conduct when the dependent variable is dichotomous (binary).  Like all regression analyses, the logistic regression is a predictive analysis.  Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more nominal, ordinal, interval or ratio-level independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff1ba90e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f5d12b",
   "metadata": {},
   "source": [
    "Above we have the Random Forest Classifier. Random Forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is controlled with the max_samples parameter if bootstrap=True (default), otherwise the whole dataset is used to build each tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8d7162",
   "metadata": {},
   "source": [
    "Now let's predict and get avaluated the models in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdfed73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_ypred = lr.predict(X_test)\n",
    "rfc_ypred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cfcd30",
   "metadata": {},
   "source": [
    "The r2_score function shows us in percentage how much the resources used to create the model, explain the predicted values. We will use r2_score for bring out that percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd014176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.273200792121834"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2_score(y_test, lr_ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e055a33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.15004623470464384"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2_score(y_test, rfc_ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e4d429",
   "metadata": {},
   "source": [
    "As we can see, ours models had a very low score. Let's use others functions... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cda00dea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89      2813\n",
      "           1       0.43      0.07      0.13       687\n",
      "\n",
      "    accuracy                           0.80      3500\n",
      "   macro avg       0.62      0.53      0.51      3500\n",
      "weighted avg       0.74      0.80      0.74      3500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, lr_ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49235576",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90      2813\n",
      "           1       1.00      0.08      0.14       687\n",
      "\n",
      "    accuracy                           0.82      3500\n",
      "   macro avg       0.91      0.54      0.52      3500\n",
      "weighted avg       0.85      0.82      0.75      3500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, rfc_ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aeed4d",
   "metadata": {},
   "source": [
    "Recall is the model's ability to find all positive instances. The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. This is all that we need know about the function classification_report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d9c804",
   "metadata": {},
   "source": [
    "For recall, let's use other alternative. The method ROC (Receiver Operating Characteristic Curve) that use TPR (True Positive Rate or Recall) and the FPR (False Positive Rate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "69b94163",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC: 0.53\n"
     ]
    }
   ],
   "source": [
    "print('ROC: %0.2f' % metrics.roc_auc_score(y_test, lr_ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2e21705f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC: 0.54\n"
     ]
    }
   ],
   "source": [
    "print('ROC: %0.2f' % metrics.roc_auc_score(y_test, rfc_ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac486e41",
   "metadata": {},
   "source": [
    "We have 53% of ROC in the model Logistic Regression, and 54% in the Random Forest Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63618927",
   "metadata": {},
   "source": [
    "Even here, we can see that the model Random Forest Classifier is a model more appropriate for this dataset than the Logistic Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdee604",
   "metadata": {},
   "source": [
    "Now let's get creating another good classfication's model, this model is called SVM(Support Vector Machines). Let's use a standardization for eliminate some discrepancies in the data, the StandardScaler will help us to converge the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad2d99fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('svc', SVC(gamma='auto'))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msvc = make_pipeline(preprocessing.StandardScaler(), SVC(gamma='auto'))\n",
    "msvc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3926c24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "msvc_ypred = msvc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9cb3fe4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10169616942755388\n"
     ]
    }
   ],
   "source": [
    "print(metrics.r2_score(y_test, msvc_ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "570d5d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92      2813\n",
      "           1       0.79      0.38      0.51       687\n",
      "\n",
      "    accuracy                           0.86      3500\n",
      "   macro avg       0.83      0.68      0.71      3500\n",
      "weighted avg       0.85      0.86      0.84      3500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, msvc_ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d756c17c",
   "metadata": {},
   "source": [
    "As we had seen in the previous models, the best r2_score was from Random Forest Classifier with -15%, and as we can see above, the model SVC with standardization have 10% of r2_score and a classifican report better than the previous models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d71bbde",
   "metadata": {},
   "source": [
    "Let's create the Random Forest Classifier again, but at this time using standardization too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f8c70f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(max_depth=2))])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrfc = make_pipeline(preprocessing.StandardScaler(), RandomForestClassifier(max_depth= 2))\n",
    "mrfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ddb7ba60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.14823513827203794\n"
     ]
    }
   ],
   "source": [
    "print(metrics.r2_score(y_test, mrfc_ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bc0fc37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90      2813\n",
      "           1       1.00      0.08      0.14       687\n",
      "\n",
      "    accuracy                           0.82      3500\n",
      "   macro avg       0.91      0.54      0.52      3500\n",
      "weighted avg       0.85      0.82      0.75      3500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mrfc_ypred = mrfc.predict(X_test)\n",
    "print(metrics.classification_report(y_test, mrfc_ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352af7df",
   "metadata": {},
   "source": [
    "With the values above, we verified that SVC is definately better than Random Forest for get applying in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e077f5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8582857142857143\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test, msvc_ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f0443d05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.68\n"
     ]
    }
   ],
   "source": [
    "print('AUC: %0.2f' % metrics.roc_auc_score(y_test, msvc_ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d8359e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5108481262327416\n"
     ]
    }
   ],
   "source": [
    "print(metrics.f1_score(y_test, msvc_ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a980c603",
   "metadata": {},
   "source": [
    "#### The name of our model is msvc, it is ready. Some findings about our model:\n",
    "+ 85.8% of accuracy.\n",
    "+ 68% of ROC (Receiver Operating Characteristic Curve).\n",
    "+ 51% of F1-score.\n",
    "+ 10% R2-score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c1b9cb",
   "metadata": {},
   "source": [
    "## Thanks for working with me.:)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
